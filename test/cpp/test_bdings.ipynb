{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys, random\n",
    "sys.path.append(\"./build\")\n",
    "from cpp_custom_bind import *\n",
    "import torch\n",
    "\n",
    "EPS = 1e-4\n",
    "_LO_N, _HI_N = -5, 5\n",
    "_LO_R, _HI_R = 4, 10\n",
    "\n",
    "def rand_matrix(rows, cols, lo=_LO_N, hi=_HI_N):\n",
    "    return [[random.uniform(lo, hi) for _ in range(cols)] for _ in range(rows)]\n",
    "\n",
    "def rand_shape(min_r=_LO_R, max_r=_HI_R, min_c=_LO_R, max_c=_HI_R):\n",
    "    return random.randint(min_r, max_r), random.randint(min_c, max_c)\n",
    "\n",
    "def is_close(a, b, eps=EPS):\n",
    "    return torch.all(torch.abs(torch.tensor(a) - torch.tensor(b)) < eps)\n",
    "\n",
    "def sample_unary():\n",
    "    r, c = rand_shape()\n",
    "    return [rand_matrix(r, c)]\n",
    "\n",
    "def sample_binary_same():\n",
    "    r, c = rand_shape()\n",
    "    return [rand_matrix(r, c), rand_matrix(r, c)]\n",
    "\n",
    "def sample_matmul():\n",
    "    m = random.randint(4, 8)\n",
    "    k = random.randint(4, 8)\n",
    "    n = random.randint(4, 8)\n",
    "    return [rand_matrix(m, k), rand_matrix(k, n)]\n",
    "\n",
    "def _to_col_major(mat):\n",
    "    return torch.tensor(mat).T.flatten().tolist()\n",
    "\n",
    "def _from_col_major(flat, like):\n",
    "    t = torch.tensor(flat).reshape(torch.tensor(like).T.shape).T\n",
    "    return t.tolist()\n",
    "\n",
    "def make_cpp_var(mat, requires_grad=True):\n",
    "    ten = cTensor(_to_col_major(mat), list(torch.tensor(mat).shape))\n",
    "    return cVariable(ten, requires_grad)\n",
    "\n",
    "def compute_grads(cpp_op, torch_op, mats, *extra):\n",
    "    torch_vars = [torch.tensor(m, dtype=torch.float64, requires_grad=True) for m in mats]\n",
    "    torch_out = torch_op(*torch_vars, *extra)\n",
    "    torch_out.backward(torch.ones_like(torch_out, dtype=torch.float64))\n",
    "    torch_grads = [v.grad.tolist() for v in torch_vars]\n",
    "    cpp_vars = [make_cpp_var(m) for m in mats]\n",
    "    cpp_op(*cpp_vars, *extra)\n",
    "    cpp_grads = [_from_col_major(v.grad.data, m) for v, m in zip(cpp_vars, mats)]\n",
    "    return cpp_grads, torch_grads\n",
    "\n",
    "def run_test(name, cpp_op, torch_op, sampler, *extra):\n",
    "    mats = sampler()\n",
    "    cpp_grads, torch_grads = compute_grads(cpp_op, torch_op, mats, *extra)\n",
    "    for cg, tg in zip(cpp_grads, torch_grads):\n",
    "        if not is_close(cg, tg):\n",
    "            print(cg)\n",
    "            print(tg)\n",
    "        assert is_close(cg, tg), f\"{name} failed, {torch.max(torch.abs(torch.tensor(cg) - torch.tensor(tg)))}\"\n",
    "\n",
    "TEST_CASES = [\n",
    "    (\"add\", add, torch.add, sample_binary_same),\n",
    "    (\"sub\", sub, torch.sub, sample_binary_same),\n",
    "    (\"mul\", mul, torch.mul, sample_binary_same),\n",
    "    (\"div\", div, torch.div, sample_binary_same),\n",
    "    (\"relu\", relu, torch.relu, sample_unary),\n",
    "    (\"exp\", exp, torch.exp, sample_unary),\n",
    "    (\"log\", log, torch.log, sample_unary),\n",
    "    (\"matmul\", matmul, torch.matmul, sample_matmul),\n",
    "    (\"transpose\", transpose, lambda x: x.T, sample_unary),\n",
    "    (\"sum_axis0\", lambda x, axis: sum(x, axis), lambda t, axis: torch.sum(t, dim=axis), sample_unary, 0),\n",
    "    (\"sum_axis1\", lambda x, axis: sum(x, axis), lambda t, axis: torch.sum(t, dim=axis), sample_unary, 1),\n",
    "]\n",
    "\n",
    "for case in TEST_CASES:\n",
    "    name, cpp_op, torch_op, sampler, *extra = case\n",
    "    run_test(name, cpp_op, torch_op, sampler, *extra)\n",
    "\n",
    "print(\"All gradient checks passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# def sample_matmul():\n",
    "#     m = random.randint(2, 4)\n",
    "#     k = random.randint(2, 4)\n",
    "#     n = random.randint(2, 4)\n",
    "#     return [rand_matrix(m, k), rand_matrix(k, n)]\n",
    "\n",
    "# def run_test(name, cpp_op, torch_op, sampler, *extra):\n",
    "#     mats = sampler()\n",
    "#     print(mats)\n",
    "#     cpp_grads, torch_grads = compute_grads(cpp_op, torch_op, mats, *extra)\n",
    "#     for cg, tg in zip(cpp_grads, torch_grads):\n",
    "#         # if not is_close(cg, tg):\n",
    "#             # print(cg)\n",
    "#             # print(tg)\n",
    "#         assert is_close(cg, tg), f\"{name} failed, {torch.max(torch.abs(torch.tensor(cg) - torch.tensor(tg)))}\"\n",
    "\n",
    "# TEST_CASES = [\n",
    "#     (\"matmul\", matmul, torch.matmul, sample_matmul),\n",
    "# ]\n",
    "\n",
    "# for case in TEST_CASES:\n",
    "#     name, cpp_op, torch_op, sampler, *extra = case\n",
    "#     run_test(name, cpp_op, torch_op, sampler, *extra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\n",
    "    [\n",
    "        [0.2798084577493345, 0.1950287748975752, 2.641156692381049], \n",
    "        [-2.180755062940427, -2.9476588252083333, -3.439144517638464], \n",
    "        [0.7676811973453912, -4.243946484894571, 0.07642422312808428], \n",
    "        [4.096629629964319, -0.33849214082704293, -4.320192427223665]\n",
    "    ], \n",
    "    [\n",
    "        [2.3553019565061906, 4.876278606797694, 1.1949820896690238], \n",
    "        [1.6327891227203306, -3.521088922961221, 4.180194907040326], \n",
    "        [1.649482501785445, -0.28169614461713444, -1.7598805700537392]\n",
    "    ]\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
