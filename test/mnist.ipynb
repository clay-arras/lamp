{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from micrograd_engine import Value\n",
    "from micrograd_nn import Neuron, Layer, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nin = 28 * 28\n",
    "nouts = [128, 64]\n",
    "\n",
    "layers = []\n",
    "prev = nin\n",
    "for i in nouts:\n",
    "    layers.append(Layer(prev, i))\n",
    "    prev = i\n",
    "outlayer = Layer(64, 10)\n",
    "\n",
    "def call(x): # returns list of len 10\n",
    "    y = x\n",
    "    for i in layers:\n",
    "        y = i(y)\n",
    "    return softmax(outlayer(y))\n",
    "\n",
    "def softmax(x):\n",
    "    # 10 values\n",
    "    epsilon = 0.000001\n",
    "    denom = sum([i.exp() for i in x], epsilon)\n",
    "    return [i.exp()/denom for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = open(\"/home/nlin/workspace/code/work/ml_zero_to_hero/data/mnist_train_short.csv\")\n",
    "reader = csv.reader(csvfile)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "next(reader)\n",
    "for row in reader:\n",
    "    row = [float(i) for i in row]\n",
    "    data.append([i * 1.0/255 for i in row[1:]])\n",
    "    labels.append([1 if row[0] == i else 0 for i in range(10)])\n",
    "\n",
    "xs = data\n",
    "ys = labels\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "alpha = 0.01\n",
    "start = time.time()\n",
    "\n",
    "for i in range(10000):\n",
    "    ypred = [call(x) for x in xs]\n",
    "    print(f\"YPRED {(time.time() - start):.1f}\")\n",
    "\n",
    "    loss = Value(0.0)\n",
    "    for y, yp in zip(ys, ypred): # y and yp are len 10 lists\n",
    "        this_example = sum(y * yp.log()) \n",
    "    print(f\"LOSS {(time.time() - start):.1f}\")\n",
    "\n",
    "    # print(\"Loss: \", loss.data)\n",
    "    loss.backward()\n",
    "    params = []\n",
    "    print(f\"BACK {(time.time() - start):.1f}\")\n",
    "    for p in layers.parameters():\n",
    "        params.extend(p)\n",
    "    for p in outlayer.parameters():\n",
    "        params.extend(p)\n",
    "\n",
    "    for value in params:\n",
    "        value.data -= alpha * value.grad\n",
    "        value.grad = 0.0\n",
    "    print(f\"PARAMS {(time.time() - start):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
